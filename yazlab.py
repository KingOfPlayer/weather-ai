# -*- coding: utf-8 -*-
"""Yazlab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18GSl5PtQnZrLj1NpByhLgINp7qCoh--a
"""

!pip install einop local-attention matplotlib numpy pandas patool reformer-pytorch scikit-learn scipy sktime sympy torch tqdm torchmetrics

!git clone https://github.com/thuml/Time-Series-Library.git

import sys
if not 'Time-Series-Library' in sys.path:
    sys.path += ['Time-Series-Library']

import copy
import torch
from types import SimpleNamespace

Configs = SimpleNamespace()

Configs.task_name = "long_term_forecast"
Configs.data = 'LTBQ0_train'
Configs.root_path = './'
Configs.data_path = 'LTBQ0_train.csv'
Configs.validate_data = 'LTBQ0_validate'
Configs.validate_data_path = 'LTBQ0_validate.csv'
Configs.device='cuda' if torch.cuda.is_available() else 'cpu'
Configs.learning_rate = 0.001

Configs.enc_in=8
Configs.dec_in=8
Configs.c_out=1
Configs.seq_len=96
Configs.label_len=48
Configs.pred_len=24
Configs.factor=5
Configs.d_model=128
Configs.n_heads=64
Configs.e_layers=2
Configs.d_layers=1
Configs.d_ff=256
Configs.attn='prob'
Configs.embed='fixed'
Configs.freq='h'
Configs.distil=True
Configs.activation='gelu'
Configs.output_attention=False
Configs.dropout=0.1
Configs.augmentation_ratio = 0

"""# Dataset Preparation"""

from data_provider.data_loader import Dataset_Custom
from torch.utils.data import DataLoader
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler

DatasetJsonFile = "LTBQ0_filled.json"

dataset = pd.read_json(DatasetJsonFile)

dataset = dataset.dropna()

#conditionfs = pd.get_dummies(dataset['condition'], prefix='condition')
#all_conditions = [f"condition_{i}.0" for i in range(1, 28)]
#for condition in all_conditions:
#  if condition not in conditionfs:
#    conditionfs[condition] = False
#dataset = dataset.drop('condition', axis=1)
#dataset = pd.concat([dataset, conditionfs], axis=1)

scaler = MinMaxScaler()

dataset['totalPrecipitation'] = scaler.fit_transform(dataset[['totalPrecipitation']])
dataset['windSpeed'] = scaler.fit_transform(dataset[['windSpeed']])
dataset['pressure'] = scaler.fit_transform(dataset[['pressure']])
dataset['humidity'] = scaler.fit_transform(dataset[['humidity']])
dataset['windDir'] = scaler.fit_transform(dataset[['windDir']])

#Clear gaps
gaps = (dataset.index.diff()>timedelta(hours=1))
dataset_chunks = []
s = 0
for index,gap in enumerate(gaps):
    if gap or index == len(gaps)-1:
        dataset_chunks.append(dataset[s:index])
        s = index

dataset_chunks[0].to_csv("LTBQ0_train.csv", index=True,index_label="date")
dataset_chunks[1].to_csv("LTBQ0_validate.csv", index=True,index_label="date")

df = pd.read_csv(Configs.data_path)
df.head()

df = pd.read_csv(Configs.validate_data_path)
df.head()

Data = Dataset_Custom
timeenc = 1
shuffle_flag = False; drop_last = True; batch_size = 128

train_data_set = Data(Configs,
    root_path=Configs.root_path,
    data_path=Configs.data_path,
    flag='train',
    size=[Configs.seq_len, Configs.label_len, Configs.pred_len],
    features="M",
    timeenc=timeenc,
    target='temp',
    freq='H',
    scale=False
)
train_data_loader = DataLoader(
    train_data_set,
    batch_size=batch_size,
    shuffle=shuffle_flag,
    num_workers=0,
    drop_last=drop_last)

validate_data_set = Data(Configs,
    root_path=Configs.root_path,
    data_path=Configs.validate_data_path,
    flag='val',
    size=[Configs.seq_len, Configs.label_len, Configs.pred_len],
    features="M",
    timeenc=timeenc,
    target='temp',
    freq='H',
    scale=False
)
validate_data_loader = DataLoader(
    validate_data_set,
    batch_size=batch_size,
    shuffle=shuffle_flag,
    num_workers=0,
    drop_last=drop_last)

test_data_set = Data(Configs,
    root_path=Configs.root_path,
    data_path=Configs.validate_data_path,
    flag='test',
    size=[Configs.seq_len, Configs.label_len, Configs.pred_len],
    features="M",
    timeenc=timeenc,
    target='temp',
    freq='H',
    scale=False
)
test_data_loader = DataLoader(
    validate_data_set,
    batch_size=batch_size,
    shuffle=shuffle_flag,
    num_workers=0,
    drop_last=drop_last)

"""# Models"""

import torch.nn as nn

"""## Informer"""

from models.Informer import Model as Informer

InformerConfigs = copy.copy(Configs)

InformerModel = Informer(InformerConfigs)
if Configs.device == 'cuda':
    InformerModel = nn.DataParallel(InformerModel, device_ids=[0])

"""## Reformer"""

from models.Reformer import Model as Reformer

ReformerConfigs = copy.copy(Configs)

ReformerModel = Reformer(ReformerConfigs)
if Configs.device == 'cuda':
    ReformerModel = nn.DataParallel(ReformerModel, device_ids=[0])

"""## Autoformer"""

from models.Autoformer import Model as Autoformer

AutoformerConfigs = copy.copy(Configs)
AutoformerConfigs.moving_avg = 25

AutoformerModel = Autoformer(AutoformerConfigs)
if Configs.device == 'cuda':
    AutoformerModel = nn.DataParallel(AutoformerModel, device_ids=[0])

"""## TemporalFusionTransformer"""

#from models.TemporalFusionTransformer import Model as TemporalFusionTransformer
import models.TemporalFusionTransformer
from collections import namedtuple
TypePos = namedtuple('TypePos', ['static', 'observed'])
models.TemporalFusionTransformer.datatype_dict = {Configs.data: TypePos([], [x for x in range(Configs.enc_in)])}


TemporalFusionTransformerConfigs = copy.copy(Configs)
TemporalFusionTransformerConfigs.d_model = 16
TemporalFusionTransformerConfigs.n_heads = 8

# Model olu≈üturma
TemporalFusionTransformerModel = models.TemporalFusionTransformer.Model(TemporalFusionTransformerConfigs)
if Configs.device == 'cuda':
    TemporalFusionTransformerModel = nn.DataParallel(TemporalFusionTransformerModel, device_ids=[0])

"""## FEDformer"""

from models.FEDformer import Model as FEDformer

FEDformerConfigs = copy.copy(Configs)
FEDformerConfigs.moving_avg = 25

FEDformerModel = FEDformer(FEDformerConfigs)
if Configs.device == 'cuda':
    FEDformerModel = nn.DataParallel(FEDformerModel, device_ids=[0])

"""# Model Loops"""

import torch
import torch.optim as optim
import numpy as np
import time
from datetime import datetime
from torchmetrics import MeanSquaredError, MeanAbsolutePercentageError, MeanAbsoluteError, R2Score

"""## Validate"""

def ValidateLoop(model,validate_data_loader,config):
    validate_loss = [];
    criterion = torch.nn.MSELoss()

    device = torch.device(config.device)
    with torch.no_grad():
        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(validate_data_loader):
            batch_x = batch_x.float().to(device)
            batch_y = batch_y.float()

            batch_x_mark = batch_x_mark.float().to(device)
            batch_y_mark = batch_y_mark.float().to(device)

            # decoder input
            dec_inp = torch.zeros([batch_y.shape[0], config.pred_len, batch_y.shape[-1]]).float()
            dec_inp = torch.cat([batch_y[:,:config.label_len,:], dec_inp], dim=1).float().to(device)
            # encoder - decoder
            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
            outputs = outputs[:, -config.pred_len:, -1:]
            batch_y = batch_y[:,-config.pred_len:,-1:].to(device)

            pred = outputs.detach().cpu()
            true = batch_y.detach().cpu()

            loss = criterion(pred, true)
            validate_loss.append(loss.item())
    total_loss = np.average(validate_loss)
    return total_loss

"""## Train Loop"""

def TrainLoop(model,train_data_loader,validate_data_loader,config,epoch):
    train_loss = [];
    validate_loss = [];

    criterion = torch.nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)

    device = torch.device(config.device)
    startTime = time.time()
    print(f"Train Started at {datetime.fromtimestamp(startTime).strftime('%Y-%m-%d %H:%M:%S.%f')}")
    for epoch in range(epoch):
        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_data_loader):
            optimizer.zero_grad()

            batch_x = batch_x.float().to(device)
            batch_y = batch_y.float()

            batch_x_mark = batch_x_mark.float().to(device)
            batch_y_mark = batch_y_mark.float().to(device)

            # decoder input
            dec_inp = torch.zeros([batch_y.shape[0], config.pred_len, batch_y.shape[-1]]).float()
            dec_inp = torch.cat([batch_y[:,:config.label_len,:], dec_inp], dim=1).float().to(device)
            # encoder - decoder
            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
            outputs = outputs[:, -config.pred_len:, -1:]
            batch_y = batch_y[:,-config.pred_len:,-1:].to(device)

            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
        v_loss = ValidateLoop(model,validate_data_loader,config)
        print(f"Epoch {epoch + 1}, Train Loss: {loss.item()}, Validate Loss: {v_loss}")
        train_loss.append(loss.item())
        validate_loss.append(v_loss)

    endTime = time.time()
    durationTime = endTime - startTime
    print(f"Train Ended at {datetime.fromtimestamp(endTime).strftime('%Y-%m-%d %H:%M:%S.%f')}")
    print(f"Train Duration {durationTime:.6f} seconds")

    return train_loss,validate_loss,durationTime

"""## Test Loop"""

def TestLoop(model,test_data_loader,config):
    MSE_loss = []
    MAPE_loss = []
    MAE_loss = []
    R_Squared_loss = []

    mse = MeanSquaredError()
    mape = MeanAbsolutePercentageError()
    mae = MeanAbsoluteError()
    r2 = R2Score()

    device = torch.device(config.device)
    with torch.no_grad():
        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(validate_data_loader):
            batch_x = batch_x.float().to(device)
            batch_y = batch_y.float()

            batch_x_mark = batch_x_mark.float().to(device)
            batch_y_mark = batch_y_mark.float().to(device)

            # decoder input
            dec_inp = torch.zeros([batch_y.shape[0], config.pred_len, batch_y.shape[-1]]).float()
            dec_inp = torch.cat([batch_y[:,:config.label_len,:], dec_inp], dim=1).float().to(device)
            # encoder - decoder
            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
            outputs = outputs[:, -config.pred_len:, -1:]
            batch_y = batch_y[:,-config.pred_len:,-1:].to(device)

            pred = outputs.detach().cpu()[:,:,0]
            true = batch_y.detach().cpu()[:,:,0]
            mse_loss = mse(pred, true)
            mape_loss = mape(pred, true)
            mae_loss = mae(pred, true)
            r2_loss = r2(pred, true)

            MSE_loss.append(mse_loss.item())
            MAPE_loss.append(mape_loss.item())
            MAE_loss.append(mae_loss.item())
            R_Squared_loss.append(r2_loss.item())

    total_MSE_loss = np.average(MSE_loss)
    total_MAPE_loss = np.average(MAPE_loss)
    total_MAE_loss = np.average(MAE_loss)
    total_R_Squared_loss = np.average(R_Squared_loss)
    return total_MSE_loss,total_MAPE_loss,total_MAE_loss,total_R_Squared_loss

"""## Predict"""

def PredictLoop(model,data_loader,config):
    device = torch.device(config.device)

    preds = []
    trues = []

    startTime = time.time()
    print(f"Predict Started at {datetime.fromtimestamp(startTime).strftime('%Y-%m-%d %H:%M:%S.%f')}")
    with torch.no_grad():
        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(data_loader):
            batch_x = batch_x.float().to(device)
            batch_y = batch_y.float()

            batch_x_mark = batch_x_mark.float().to(device)
            batch_y_mark = batch_y_mark.float().to(device)

            # decoder input
            dec_inp = torch.zeros([batch_y.shape[0], config.pred_len, batch_y.shape[-1]]).float()
            dec_inp = torch.cat([batch_y[:,:config.label_len,:], dec_inp], dim=1).float().to(device)
            # encoder - decoder
            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
            outputs = outputs[:, -config.pred_len:, -1:]
            batch_y = batch_y[:,-config.pred_len:,-1:].to(device)

            pred = outputs.detach().cpu()[:,:,0]
            true = batch_y.detach().cpu()[:,:,0]

            preds.append(pred)
            trues.append(true)

    endTime = time.time()
    durationTime = endTime - startTime
    print(f"Predict Ended at {datetime.fromtimestamp(endTime).strftime('%Y-%m-%d %H:%M:%S.%f')}")
    print(f"Predict Duration {durationTime:.6f} seconds")

    preds = np.array(preds)
    trues = np.array(trues)

    return preds,trues

"""# Models Trains and Test

## Informer
"""

Informer_train_loss,Informer_validate_loss,Informer_durationTime = TrainLoop(InformerModel,train_data_loader,validate_data_loader,InformerConfigs,25)
Informer_MSE_loss,Informer_MAPE_loss,Informer_MAE_loss,Informer_R_Squared_loss = TestLoop(InformerModel,test_data_loader,InformerConfigs)

"""## Reformer"""

Reformer_train_loss,Reformer_validate_loss,Reformer_durationTime = TrainLoop(ReformerModel,train_data_loader,validate_data_loader,ReformerConfigs,25)
Reformer_MSE_loss,Reformer_MAPE_loss,Reformer_MAE_loss,Reformer_R_Squared_loss = TestLoop(ReformerModel,test_data_loader,ReformerConfigs)

"""## AutoFormer"""

Autoformer_train_loss,Autoformer_validate_loss,Autoformer_durationTime = TrainLoop(AutoformerModel,train_data_loader,validate_data_loader,AutoformerConfigs,25)
Autoformer_MSE_loss,Autoformer_MAPE_loss,Autoformer_MAE_loss,Autoformer_R_Squared_loss = TestLoop(AutoformerModel,test_data_loader,AutoformerConfigs)

"""## TemporalFusionTransformer"""

TemporalFusionTransformerModel_train_loss,TemporalFusionTransformerModel_validate_loss,TemporalFusionTransformerModel_durationTime = TrainLoop(TemporalFusionTransformerModel,train_data_loader,validate_data_loader,TemporalFusionTransformerConfigs,25)
TemporalFusionTransformerModel_MSE_loss,TemporalFusionTransformerModel_MAPE_loss,TemporalFusionTransformerModel_MAE_loss,TemporalFusionTransformerModel_R_Squared_loss = TestLoop(TemporalFusionTransformerModel,test_data_loader,TemporalFusionTransformerConfigs)

"""## FEDformer"""

FEDformerModel_train_loss,FEDformerModel_validate_loss,FEDformerModel_durationTime = TrainLoop(FEDformerModel,train_data_loader,validate_data_loader,FEDformerConfigs,25)
FEDformerModel_MSE_loss,FEDformerModel_MAPE_loss,FEDformerModel_MAE_loss,FEDformerModel_R_Squared_loss = TestLoop(FEDformerModel,test_data_loader,FEDformerConfigs)

"""# Models Results

## Ploting Functions
"""

import matplotlib.pyplot as plt
import numpy as np

def PlotTrainGraph(train_loss,validate_loss,model_name):

    x = range(len(train_loss))
    plt.title(f'Epoch vs Loss ({model_name})')
    plt.plot(x, train_loss, label = "Train Loss")
    plt.plot(x, validate_loss, label = "Validate Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

def PlotModelStatistics(model_names,MSE_loss,MAPE_loss,MAE_loss,R_Squared_loss):
    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py
    model_labels = model_names
    statistics = {
        'MSE': MSE_loss,
        'MAPE': MAPE_loss,
        'MAE': MAE_loss,
        'R Squared': R_Squared_loss
    }

    x = np.arange(len(model_labels))
    width = 0.2
    multiplier = 0
    fig, ax = plt.subplots(figsize=(12, 6),layout='constrained')

    for attribute, measurement in statistics.items():
        offset = width * multiplier
        rects = ax.bar(x + offset, measurement, width, label=attribute)
        ax.bar_label(rects, padding=3)
        multiplier += 1

    ax.set_title('Models Statistics')
    ax.set_xticks(x + width, model_labels)
    ax.legend(loc='upper left', ncols=3)

    plt.show()

def PlotPretitionGraph(preds,trues,day_index,model_name):

    x = range(preds[0,day_index,:].shape[0])
    plt.title(f'Temperature Prediction ({model_name})')
    plt.plot(x, preds[0,day_index,:], label = "Prediction")
    plt.plot(x, trues[0,day_index,:], label = "Real Data")
    plt.xlabel("Temperature")
    plt.ylabel("Hour")
    plt.legend()
    plt.show()

"""## Epoch vs Loss Plots"""

PlotTrainGraph(Informer_train_loss,Informer_validate_loss,"Informer")
PlotTrainGraph(Reformer_train_loss,Reformer_validate_loss,"Reformer")
PlotTrainGraph(Autoformer_train_loss,Autoformer_validate_loss,"Autoformer")
PlotTrainGraph(TemporalFusionTransformerModel_train_loss,TemporalFusionTransformerModel_validate_loss,"Temporal Fusion Transformer Model")
PlotTrainGraph(FEDformerModel_train_loss,FEDformerModel_validate_loss,"FEDformer Model")

"""## Models Statistics"""

PlotModelStatistics(
    model_names=["Informer","Reformer","Autoformer","Temporal Fusion Transformer Model","FEDformer Model"]
    ,MSE_loss=[Informer_MSE_loss,Reformer_MSE_loss,Autoformer_MSE_loss,TemporalFusionTransformerModel_MSE_loss,FEDformerModel_MSE_loss]
    ,MAPE_loss=[Informer_MAPE_loss,Reformer_MAPE_loss,Autoformer_MAPE_loss,TemporalFusionTransformerModel_MAPE_loss,FEDformerModel_MAPE_loss]
    ,MAE_loss=[Informer_MAE_loss,Reformer_MAE_loss,Autoformer_MAE_loss,TemporalFusionTransformerModel_MAE_loss,FEDformerModel_MAE_loss]
    ,R_Squared_loss=[Informer_R_Squared_loss,Reformer_R_Squared_loss,Autoformer_R_Squared_loss,TemporalFusionTransformerModel_R_Squared_loss,FEDformerModel_R_Squared_loss]
    )

"""## Models Prediction"""

Informer_preds,Informer_trues = PredictLoop(InformerModel,test_data_loader,Configs)

Reformer_preds,Reformer_trues = PredictLoop(ReformerModel,test_data_loader,Configs)

Autoformer_preds,Autoformer_trues = PredictLoop(AutoformerModel,test_data_loader,Configs)

TemporalFusionTransformerModel_preds,TemporalFusionTransformerModel_trues = PredictLoop(TemporalFusionTransformerModel,test_data_loader,Configs)

FEDformerModel_preds,FEDformerModel_trues = PredictLoop(FEDformerModel,test_data_loader,Configs)

"""## Prediction Plots"""

PlotPretitionGraph(Informer_preds,Informer_trues,0,"Informer")
PlotPretitionGraph(Reformer_preds,Reformer_trues,0,"Reformer")
PlotPretitionGraph(Autoformer_preds,Autoformer_trues,0,"Autoformer")
PlotPretitionGraph(TemporalFusionTransformerModel_preds,TemporalFusionTransformerModel_trues,0,"Temporal Fusion Transformer Model")
PlotPretitionGraph(FEDformerModel_preds,FEDformerModel_trues,0,"FEDformer Model")

"""#Save Models"""

import torch
import os
try:
  os.mkdir('models')
except FileExistsError:
  print(f"Models folder exist.")
torch.save(InformerModel.state_dict(), 'models/informer_model.pth')
torch.save(ReformerModel.state_dict(), 'models/reformer_model.pth')
torch.save(AutoformerModel.state_dict(), 'models/autoformer_model.pth')
torch.save(TemporalFusionTransformerModel.state_dict(), 'models/tft_model.pth')
torch.save(FEDformerModel.state_dict(), 'models/fedformer_model.pth')
print("Models Saved")